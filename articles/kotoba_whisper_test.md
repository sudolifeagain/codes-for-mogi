---
title: kotoba-whisperã‚’ä½¿ã£ã¦ã¿ã‚‹
emoji: ğŸ˜¸
type: tech
topics: [Huggingface, AI]
published: false
---

## æ¦‚è¦
kootba whisperã‚’ä½¿ã£ã¦ã¿ãŸã®ã§powershellã§ã®ã‚³ãƒãƒ³ãƒ‰æ“ä½œã‚’ã¾ã¨ã‚ã¦ãŠã


### Powershellä¸Šã®å‹•ä½œ
```powershell
Windows PowerShell
Copyright (C) Microsoft Corporation. All rights reserved.

æ–°æ©Ÿèƒ½ã¨æ”¹å–„ã®ãŸã‚ã«æœ€æ–°ã® PowerShell ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„!https://aka.ms/PSWindows

PS C:\Users\YN> vi ~/.bash_profile
vi : ç”¨èª 'vi' ã¯ã€ã‚³ãƒãƒ³ãƒ‰ãƒ¬ãƒƒãƒˆã€é–¢æ•°ã€ã‚¹ã‚¯ãƒªãƒ—ãƒˆ ãƒ•ã‚¡ã‚¤ãƒ«ã€ã¾ãŸã¯æ“ä½œå¯èƒ½ãªãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®åå‰ã¨ã—ã¦èªè­˜ã•ã‚Œã¾ã›ã‚“ã€‚å
å‰ãŒæ­£ã—ãè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã€ãƒ‘ã‚¹ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯ãã®ãƒ‘ã‚¹ãŒæ­£ã—ã„ã“ã¨ã‚’ç¢ºèªã—ã¦ã‹ã‚‰ã€å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚
ç™ºç”Ÿå ´æ‰€ è¡Œ:1 æ–‡å­—:1
+ vi ~/.bash_profile
+ ~~
    + CategoryInfo          : ObjectNotFound: (vi:String) [], CommandNotFoundException
    + FullyQualifiedErrorId : CommandNotFoundException

PS C:\Users\YN> cd ~
PS C:\Users\YN> cd~
cd~ : ç”¨èª 'cd~' ã¯ã€ã‚³ãƒãƒ³ãƒ‰ãƒ¬ãƒƒãƒˆã€é–¢æ•°ã€ã‚¹ã‚¯ãƒªãƒ—ãƒˆ ãƒ•ã‚¡ã‚¤ãƒ«ã€ã¾ãŸã¯æ“ä½œå¯èƒ½ãªãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®åå‰ã¨ã—ã¦èªè­˜ã•ã‚Œã¾ã›ã‚“ã€‚
åå‰ãŒæ­£ã—ãè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã€ãƒ‘ã‚¹ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯ãã®ãƒ‘ã‚¹ãŒæ­£ã—ã„ã“ã¨ã‚’ç¢ºèªã—ã¦ã‹ã‚‰ã€å†è©¦è¡Œã—ã¦ãã ã•ã„
ã€‚
ç™ºç”Ÿå ´æ‰€ è¡Œ:1 æ–‡å­—:1
+ cd~
+ ~~~
    + CategoryInfo          : ObjectNotFound: (cd~:String) [], CommandNotFoundException
    + FullyQualifiedErrorId : CommandNotFoundException

PS C:\Users\YN> mkdir huggingface_project


    ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: C:\Users\YN


Mode                 LastWriteTime         Length Name
----                 -------------         ------ ----
d-----        2024/12/23      1:46                huggingface_project


PS C:\Users\YN> cd huggingface_project
PS C:\Users\YN\huggingface_project> python3 -m venv venv
Python
PS C:\Users\YN\huggingface_project> python3 -m venv venv
Python
PS C:\Users\YN\huggingface_project> python3 --version
Python
PS C:\Users\YN\huggingface_project> python -m venv venv
PS C:\Users\YN\huggingface_project> source venv/bin/activate
source : ç”¨èª 'source' ã¯ã€ã‚³ãƒãƒ³ãƒ‰ãƒ¬ãƒƒãƒˆã€é–¢æ•°ã€ã‚¹ã‚¯ãƒªãƒ—ãƒˆ ãƒ•ã‚¡ã‚¤ãƒ«ã€ã¾ãŸã¯æ“ä½œå¯èƒ½ãªãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®åå‰ã¨ã—ã¦èªè­˜ã•ã‚Œã¾
ã›ã‚“ã€‚åå‰ãŒæ­£ã—ãè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã€ãƒ‘ã‚¹ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯ãã®ãƒ‘ã‚¹ãŒæ­£ã—ã„ã“ã¨ã‚’ç¢ºèªã—ã¦ã‹ã‚‰ã€å†è©¦è¡Œã—ã¦ã
ã ã•ã„ã€‚
ç™ºç”Ÿå ´æ‰€ è¡Œ:1 æ–‡å­—:1
+ source venv/bin/activate
+ ~~~~~~
    + CategoryInfo          : ObjectNotFound: (source:String) [], CommandNotFoundException
    + FullyQualifiedErrorId : CommandNotFoundException

PS C:\Users\YN\huggingface_project> .\venv\Scripts\Activate.ps1
.\venv\Scripts\Activate.ps1 : ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã§ã¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å®Ÿè¡ŒãŒç„¡åŠ¹ã«ãªã£ã¦ã„ã‚‹ãŸã‚ã€ãƒ•ã‚¡ã‚¤ãƒ« C:\Users\YN\huggingface_
project\venv\Scripts\Activate.ps1 ã‚’èª­ã¿è¾¼ã‚€ã“ã¨ãŒã§ãã¾ã›ã‚“ã€‚è©³ç´°ã«ã¤ã„ã¦ã¯ã€ã€Œabout_Execution_Policiesã€(https://go.m
icrosoft.com/fwlink/?LinkID=135170) ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚
ç™ºç”Ÿå ´æ‰€ è¡Œ:1 æ–‡å­—:1
+ .\venv\Scripts\Activate.ps1
+ ~~~~~~~~~~~~~~~~~~~~~~~~~~~
    + CategoryInfo          : ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ ã‚¨ãƒ©ãƒ¼: (: ) []ã€PSSecurityException
    + FullyQualifiedErrorId : UnauthorizedAccess
PS C:\Users\YN\huggingface_project> Get-ExecutionPolicy
Restricted
PS C:\Users\YN\huggingface_project> Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass
PS C:\Users\YN\huggingface_project> Get-ExecutionPolicy
Bypass
PS C:\Users\YN\huggingface_project> .\venv\Scripts\Activate.ps1
(venv) PS C:\Users\YN\huggingface_project> code .
(venv) PS C:\Users\YN\huggingface_project> pip install faster-whisper
Collecting faster-whisper
  Downloading faster_whisper-1.1.0-py3-none-any.whl.metadata (16 kB)
Collecting ctranslate2<5,>=4.0 (from faster-whisper)
  Downloading ctranslate2-4.5.0-cp312-cp312-win_amd64.whl.metadata (10 kB)
Collecting huggingface-hub>=0.13 (from faster-whisper)
  Downloading huggingface_hub-0.27.0-py3-none-any.whl.metadata (13 kB)
Collecting tokenizers<1,>=0.13 (from faster-whisper)
  Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)
Collecting onnxruntime<2,>=1.14 (from faster-whisper)
  Downloading onnxruntime-1.20.1-cp312-cp312-win_amd64.whl.metadata (4.7 kB)
Collecting av>=11 (from faster-whisper)
  Downloading av-14.0.1-cp312-cp312-win_amd64.whl.metadata (4.6 kB)
Collecting tqdm (from faster-whisper)
  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)
Collecting setuptools (from ctranslate2<5,>=4.0->faster-whisper)
  Downloading setuptools-75.6.0-py3-none-any.whl.metadata (6.7 kB)
Collecting numpy (from ctranslate2<5,>=4.0->faster-whisper)
  Downloading numpy-2.2.1-cp312-cp312-win_amd64.whl.metadata (60 kB)
Collecting pyyaml<7,>=5.3 (from ctranslate2<5,>=4.0->faster-whisper)
  Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)
Collecting filelock (from huggingface-hub>=0.13->faster-whisper)
  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)
Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.13->faster-whisper)
  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)
Collecting packaging>=20.9 (from huggingface-hub>=0.13->faster-whisper)
  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)
Collecting requests (from huggingface-hub>=0.13->faster-whisper)
  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)
Collecting typing-extensions>=3.7.4.3 (from huggingface-hub>=0.13->faster-whisper)
  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)
Collecting coloredlogs (from onnxruntime<2,>=1.14->faster-whisper)
  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)
Collecting flatbuffers (from onnxruntime<2,>=1.14->faster-whisper)
  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)
Collecting protobuf (from onnxruntime<2,>=1.14->faster-whisper)
  Downloading protobuf-5.29.2-cp310-abi3-win_amd64.whl.metadata (592 bytes)
Collecting sympy (from onnxruntime<2,>=1.14->faster-whisper)
  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)
Collecting colorama (from tqdm->faster-whisper)
  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)
Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper)
  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)
Collecting charset-normalizer<4,>=2 (from requests->huggingface-hub>=0.13->faster-whisper)
  Using cached charset_normalizer-3.4.0-cp312-cp312-win_amd64.whl.metadata (34 kB)
Collecting idna<4,>=2.5 (from requests->huggingface-hub>=0.13->faster-whisper)
  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)
Collecting urllib3<3,>=1.21.1 (from requests->huggingface-hub>=0.13->faster-whisper)
  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)
Collecting certifi>=2017.4.17 (from requests->huggingface-hub>=0.13->faster-whisper)
  Downloading certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)
Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime<2,>=1.14->faster-whisper)
  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)
Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime<2,>=1.14->faster-whisper)
  Downloading pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)
Downloading faster_whisper-1.1.0-py3-none-any.whl (1.1 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.1/1.1 MB 11.0 MB/s eta 0:00:00
Downloading av-14.0.1-cp312-cp312-win_amd64.whl (25.8 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 25.8/25.8 MB 11.0 MB/s eta 0:00:00
Downloading ctranslate2-4.5.0-cp312-cp312-win_amd64.whl (19.5 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 19.5/19.5 MB 11.1 MB/s eta 0:00:00
Downloading huggingface_hub-0.27.0-py3-none-any.whl (450 kB)
Downloading onnxruntime-1.20.1-cp312-cp312-win_amd64.whl (11.3 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 11.3/11.3 MB 11.1 MB/s eta 0:00:00
Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2.4/2.4 MB 10.5 MB/s eta 0:00:00
Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)
Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)
Downloading numpy-2.2.1-cp312-cp312-win_amd64.whl (12.6 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 12.6/12.6 MB 11.1 MB/s eta 0:00:00
Using cached packaging-24.2-py3-none-any.whl (65 kB)
Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl (156 kB)
Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)
Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)
Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)
Using cached filelock-3.16.1-py3-none-any.whl (16 kB)
Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)
Downloading protobuf-5.29.2-cp310-abi3-win_amd64.whl (434 kB)
Using cached requests-2.32.3-py3-none-any.whl (64 kB)
Downloading setuptools-75.6.0-py3-none-any.whl (1.2 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.2/1.2 MB 10.3 MB/s eta 0:00:00
Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6.2/6.2 MB 10.5 MB/s eta 0:00:00
Downloading certifi-2024.12.14-py3-none-any.whl (164 kB)                                                                Using cached charset_normalizer-3.4.0-cp312-cp312-win_amd64.whl (102 kB)                                                Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)                                                             Using cached idna-3.10-py3-none-any.whl (70 kB)                                                                         Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)
Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)
Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)
Installing collected packages: mpmath, flatbuffers, urllib3, typing-extensions, sympy, setuptools, pyyaml, pyreadline3, protobuf, packaging, numpy, idna, fsspec, filelock, colorama, charset-normalizer, certifi, av, tqdm, requests, humanfriendly, ctranslate2, huggingface-hub, coloredlogs, tokenizers, onnxruntime, faster-whisper
Successfully installed av-14.0.1 certifi-2024.12.14 charset-normalizer-3.4.0 colorama-0.4.6 coloredlogs-15.0.1 ctranslate2-4.5.0 faster-whisper-1.1.0 filelock-3.16.1 flatbuffers-24.3.25 fsspec-2024.12.0 huggingface-hub-0.27.0 humanfriendly-10.0 idna-3.10 mpmath-1.3.0 numpy-2.2.1 onnxruntime-1.20.1 packaging-24.2 protobuf-5.29.2 pyreadline3-3.5.4 pyyaml-6.0.2 requests-2.32.3 setuptools-75.6.0 sympy-1.13.3 tokenizers-0.21.0 tqdm-4.67.1 typing-extensions-4.12.2 urllib3-2.3.0

[notice] A new release of pip is available: 24.2 -> 24.3.1
[notice] To update, run: python.exe -m pip install --upgrade pip
(venv) PS C:\Users\YN\huggingface_project> from faster_whisper import WhisperModel
ç™ºç”Ÿå ´æ‰€ è¡Œ:1 æ–‡å­—:1
+ from faster_whisper import WhisperModel
+ ~~~~
ã“ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®è¨€èªã§ã¯ã€'from' ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚
    + CategoryInfo          : ParserError: (:) [], ParentContainsErrorRecordException
    + FullyQualifiedErrorId : ReservedKeywordNotAllowed

(venv) PS C:\Users\YN\huggingface_project> wget https://huggingface.co/kotoba-tech/kotoba-whisper-v1.0-ggml/resolve/main/sample_ja_speech.wav


StatusCode        : 200
StatusDescription : OK
Content           : {82, 73, 70, 70...}
RawContent        : HTTP/1.1 200 OK
                    Connection: keep-alive
                    x-amz-storage-class: INTELLIGENT_TIERING
                    x-amz-server-side-encryption: AES256
                    x-amz-version-id: null
                    Content-Disposition: inline; filename*=UTF-8''sample_ja...
Headers           : {[Connection, keep-alive], [x-amz-storage-class, INTELLIGENT_TIERING], [x-amz-server-side-encryptio
                    n, AES256], [x-amz-version-id, null]...}
RawContentLength  : 6639070



(venv) PS C:\Users\YN\huggingface_project> from faster_whisper import WhisperModel
ç™ºç”Ÿå ´æ‰€ è¡Œ:1 æ–‡å­—:1
+ from faster_whisper import WhisperModel
+ ~~~~
ã“ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®è¨€èªã§ã¯ã€'from' ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚
    + CategoryInfo          : ParserError: (:) [], ParentContainsErrorRecordException
    + FullyQualifiedErrorId : ReservedKeywordNotAllowed

(venv) PS C:\Users\YN\huggingface_project>
(venv) PS C:\Users\YN\huggingface_project> model = WhisperModel("kotoba-tech/kotoba-whisper-v2.0-faster")
model : ç”¨èª 'model' ã¯ã€ã‚³ãƒãƒ³ãƒ‰ãƒ¬ãƒƒãƒˆã€é–¢æ•°ã€ã‚¹ã‚¯ãƒªãƒ—ãƒˆ ãƒ•ã‚¡ã‚¤ãƒ«ã€ã¾ãŸã¯æ“ä½œå¯èƒ½ãªãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®åå‰ã¨ã—ã¦èªè­˜ã•ã‚Œã¾ã›
ã‚“ã€‚åå‰ãŒæ­£ã—ãè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã€ãƒ‘ã‚¹ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯ãã®ãƒ‘ã‚¹ãŒæ­£ã—ã„ã“ã¨ã‚’ç¢ºèªã—ã¦ã‹ã‚‰ã€å†è©¦è¡Œã—ã¦ãã 
ã•ã„ã€‚
ç™ºç”Ÿå ´æ‰€ è¡Œ:1 æ–‡å­—:1
+ model = WhisperModel("kotoba-tech/kotoba-whisper-v2.0-faster")
+ ~~~~~
    + CategoryInfo          : ObjectNotFound: (model:String) [], CommandNotFoundException
    + FullyQualifiedErrorId : CommandNotFoundException

(venv) PS C:\Users\YN\huggingface_project>
(venv) PS C:\Users\YN\huggingface_project> segments, info = model.transcribe("sample_ja_speech.wav", language="ja", chunk_length=15, condition_on_previous_text=False)
ç™ºç”Ÿå ´æ‰€ è¡Œ:1 æ–‡å­—:9
+ segments, info = model.transcribe("sample_ja_speech.wav", language="j ...
+         ~
ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ä¸€è¦§ã«å¼•æ•°ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚
ç™ºç”Ÿå ´æ‰€ è¡Œ:1 æ–‡å­—:58
+ segments, info = model.transcribe("sample_ja_speech.wav", language="j ...
+                                                          ~
',' ã®å¾Œã«å¼ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚
ç™ºç”Ÿå ´æ‰€ è¡Œ:1 æ–‡å­—:59
+ ... info = model.transcribe("sample_ja_speech.wav", language="ja", chunk_ ...
+                                                     ~~~~~~~~~~~~~
å¼ã¾ãŸã¯ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆã®ãƒˆãƒ¼ã‚¯ãƒ³ 'language="ja"' ã‚’ä½¿ç”¨ã§ãã¾ã›ã‚“ã€‚
ç™ºç”Ÿå ´æ‰€ è¡Œ:1 æ–‡å­—:58
+ segments, info = model.transcribe("sample_ja_speech.wav", language="j ...
+ ... v", language="ja", chunk_length=15, condition_on_previous_text=False)
+                                                                         ~
å¼ã¾ãŸã¯ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆã®ãƒˆãƒ¼ã‚¯ãƒ³ ')' ã‚’ä½¿ç”¨ã§ãã¾ã›ã‚“ã€‚
    + CategoryInfo          : ParserError: (:) [], ParentContainsErrorRecordException
    + FullyQualifiedErrorId : MissingArgument

(venv) PS C:\Users\YN\huggingface_project> for segment in segments:
ç™ºç”Ÿå ´æ‰€ è¡Œ:1 æ–‡å­—:4
+ for segment in segments:
+    ~
ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ 'for' ã®å¾Œã«å§‹ã‚ã® '(' ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚
    + CategoryInfo          : ParserError: (:) [], ParentContainsErrorRecordException
    + FullyQualifiedErrorId : MissingOpenParenthesisAfterKeyword

(venv) PS C:\Users\YN\huggingface_project>     print("[%.2fs -> %.2fs] %s" % (segment.start, segment.end, segment.text))

ç™ºç”Ÿå ´æ‰€ è¡Œ:1 æ–‡å­—:49
+     print("[%.2fs -> %.2fs] %s" % (segment.start, segment.end, segmen ...
    + FullyQualifiedErrorId : MissingArgument

(venv) PS C:\Users\YN\huggingface_project> python
Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)] on win32
Type "help", "copyright", "credits" or "license" for more information.
>>> from faster_whisper import WhisperModel
>>>
>>> model = WhisperModel("kotoba-tech/kotoba-whisper-v2.0-faster")
preprocessor_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:00<?, ?B/s]
C:\Users\YN\huggingface_project\venv\Lib\site-packages\huggingface_hub\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\Users\YN\.cache\huggingface\hub\models--kotoba-tech--kotoba-whisper-v2.0-faster. Caching files will still work but in a degraded version that might require more  warnings.warn(message)
model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.51G/1.51G [02:17<00:00, 11.0MB/s]
get device or backend do not support efficient float16 computation. The model weights have been automatically converted to use the float32 compute type instead.
>>>
>>> segments, info = model.transcribe("sample_ja_speech.wav", language="ja", chunk_length=15, condition_on_previous_text=False)
  File "<stdin>", line 1, in <module>
  File "C:\Users\YN\huggingface_project\venv\Lib\site-packages\faster_whisper\transcribe.py", line 821, in transcribe
    audio = decode_audio(audio, sampling_rate=sampling_rate)
  File "C:\Users\YN\huggingface_project\venv\Lib\site-packages\faster_whisper\audio.py", line 46, in decode_audio
    with av.open(input_file, mode="r", metadata_errors="ignore") as container:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "av\\container\\core.pyx", line 236, in av.container.core.Container.__cinit__
  File "av\\container\\core.pyx", line 256, in av.container.core.Container.err_check
  File "av\\error.pyx", line 428, in av.error.err_check
>>> for segment in segments:
...
... dir
  File "<stdin>", line 3
    dir
<built-in function dir>
>>> import os
>>>
Current Directory: C:\Users\YN\huggingface_project
>>>
>>> # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å†…å®¹ã‚’ãƒªã‚¹ãƒˆè¡¨ç¤º
>>> print("Directory Contents:", os.listdir())
Directory Contents: ['venv']
>>> wget https://huggingface.co/kotoba-tech/kotoba-whisper-v1.0-ggml/resolve/main/sample_ja_speech.wav
  File "<stdin>", line 1
    wget https://huggingface.co/kotoba-tech/kotoba-whisper-v1.0-ggml/resolve/main/sample_ja_speech.wav
         ^^^^^
SyntaxError: invalid syntax
>>> cd
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "<stdin>", line 1, in <module>
NameError: name 'q' is not defined
>>> q
Traceback (most recent call last):
(venv) PS C:\Users\YN\huggingface_project> cd
(venv) PS C:\Users\YN\huggingface_project> python
Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)] on win32
>>>
>>> segments, info = model.transcribe("sample_ja_speech.wav", language="ja", chunk_length=15, condition_on_previous_text=False)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
    audio = decode_audio(audio, sampling_rate=sampling_rate)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\YN\huggingface_project\venv\Lib\site-packages\faster_whisper\audio.py", line 46, in decode_audio
    with av.open(input_file, mode="r", metadata_errors="ignore") as container:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "av\\container\\core.pyx", line 369, in av.container.core.open
  File "av\\container\\core.pyx", line 236, in av.container.core.Container.__cinit__
  File "av\\container\\core.pyx", line 256, in av.container.core.Container.err_check
  File "av\\error.pyx", line 428, in av.error.err_check
av.error.FileNotFoundError: [Errno 2] No such file or directory: 'sample_ja_speech.wav'
>>> for segment in segments:
...     print("[%.2fs -> %.2fs] %s" % (segment.start, segment.end, segment.text))
... import requests
  File "<stdin>", line 3
...         f.write(response.content)
...     print(f"Downloaded: {file_name}")
... else:
...     print(f"Failed to download. HTTP Status Code: {response.status_code}")
  File "<stdin>", line 7
    pip install requests
    ^^^
(venv) PS C:\Users\YN\huggingface_project> pip install requests
>>> import requests
>>>
>>> url = "https://huggingface.co/kotoba-tech/kotoba-whisper-v1.0-ggml/resolve/main/sample_ja_speech.wav"
>>> file_name = "sample_ja_speech.wav"
>>> if response.status_code == 200:
...     with open(file_name, "wb") as f:
...         f.write(response.content)
...     print(f"Failed to download. HTTP Status Code: {response.status_code}")
... import os
  File "<stdin>", line 7
>>> print("Current Directory Contents:", os.listdir())
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'os' is not defined. Did you forget to import 'os'?
Current Directory Contents: ['venv']
>>> import requests
>>>
>>>
>>> response = requests.get(url)
>>> if response.status_code == 200:
... else:
...     print(f"Failed to download. HTTP Status Code: {response.status_code}")
... from faster_whisper import WhisperModel
  File "<stdin>", line 7
    ^^^^
SyntaxError: invalid syntax
>>>
>>> model = WhisperModel("kotoba-tech/kotoba-whisper-v2.0-faster")
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'WhisperModel' is not defined
>>>
>>> segments, info = model.transcribe("sample_ja_speech.wav", language="ja", chunk_length=15, condition_on_previous_text=False)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'model' is not defined
>>> for segment in segments:
...     print("[%.2fs -> %.2fs] %s" % (segment.start, segment.end, segment.text))
... from faster_whisper import WhisperModel
  File "<stdin>", line 3
    from faster_whisper import WhisperModel
    ^^^^
SyntaxError: invalid syntax
>>>
>>> model = WhisperModel("models")
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'WhisperModel' is not defined
>>>
>>> segments, info = model.transcribe("sample_ja_speech.wav", language="ja", chunk_length=15, condition_on_previous_text=False)
Traceback (most recent call last):
...     print("[%.2fs -> %.2fs] %s" % (segment.start, segment.end, segment.text))
... quit
  File "<stdin>", line 3
(venv) PS C:\Users\YN\huggingface_project> ls


    ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: C:\Users\YN\huggingface_project
Mode                 LastWriteTime         Length Name
----                 -------------         ------ ----
d-----        2024/12/23      2:03                venv
    ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: C:\Users\YN\huggingface_project


Mode                 LastWriteTime         Length Name
d-----        2024/12/23      2:09                venv
-a----        2024/12/23      1:59        6639070 sample_ja_speech.wav


Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)] on win32
Type "help", "copyright", "credits" or "license" for more information.
>>> from faster_whisper import WhisperModel
>>>
[2024-12-23 02:09:21.464] [ctranslate2] [thread 32148] [warning] The compute type inferred from the saved model is float16, but the target device or backend do not support efficient float16 computation. The model weights have been automatically converted to use the float32 compute type instead.
>>>
>>> for segment in segments:
...     print("[%.2fs -> %.2fs] %s" % (segment.start, segment.end, segment.text))
... from faster_whisper import WhisperModel
  File "<stdin>", line 3
    from faster_whisper import WhisperModel
    ^^^^
SyntaxError: invalid syntax
>>>
>>> model = WhisperModel("kotoba-tech/kotoba-whisper-v2.0-faster")
[2024-12-23 02:35:57.476] [ctranslate2] [thread 32148] [warning] The compute type inferred from the saved model is float16, but the target device or backend do not support efficient float16 computation. The model weights have been automatically converted to use the float32 compute type instead.
>>>
>>> segments, info = model.transcribe("sample_ja_speech.wav", language="ja", chunk_length=15, condition_on_previous_text=False)
>>> for segment in segments:
...     print("[%.2fs -> %.2fs] %s" % (segment.start, segment.end, segment.text))
... quit()
  File "<stdin>", line 3
    quit()
    ^^^^
SyntaxError: invalid syntax
>>> python example.py
  File "<stdin>", line 1
    python example.py
           ^^^^^^^
SyntaxError: invalid syntax
>>> python example.py
  File "<stdin>", line 1
    python example.py
           ^^^^^^^
SyntaxError: invalid syntax
>>> python sample.py
  File "<stdin>", line 1
    python sample.py
           ^^^^^^
SyntaxError: invalid syntax
>>> exit()
(venv) PS C:\Users\YN\huggingface_project> python example.py
C:\Users\YN\AppData\Local\Programs\Python\Python312\python.exe: can't open file 'C:\\Users\\YN\\huggingface_project\\example.py': [Errno 2] No such file or directory
(venv) PS C:\Users\YN\huggingface_project> python sample.py
[2024-12-23 02:40:46.467] [ctranslate2] [thread 29248] [warning] The compute type inferred from the saved model is float16, but the target device or backend do not support efficient float16 computation. The model weights have been automatically converted to use the float32 compute type instead.
[0.00s -> 15.00s] NLP5å¹´é–“ã€ã„ã‚ã„ã‚ã‚ã£ãŸã¨æ€ã†ã‚“ã§ã™ã‘ã‚Œã©ã‚‚ã€ä»Šæ—¥ã®ãƒˆãƒ¼ã‚¯ã§ã¯ã€NLPã®éå»5å¹´é–“ã‚’ç«ç½ã®ç ”ç©¶ã§ã‚ã£ãŸã‚Šã€ç§ãŸã¡ãŒå–ã‚Šçµ„ ã‚“ã§ããŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ä¸­å¿ƒã«ã€ã¡ã‚‡ã£ã¨5å¹´é–“ã‚’ãƒªãƒ•ãƒ¬ã‚¯ãƒˆã—ã¦ã€ã©ã†ã„ã†ãã£ã‹ã‘ã§ã€è¨€è‘‰ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã‚ºã¨ã„ã†ã‹ã©ã†ã„ã†ãµã†ã«ã€
[15.00s -> 19.64s] ãã‚‚ãã‚‚èª°ã‚„ã£ã¦ã„ã†è©±ã ã£ãŸã‹ãªã¨æ€ã†ã‚“ã§ã™
[30.00s -> 45.00s] ç§ã€ä»Šå¹´ã€ã‚³ãƒ³ãƒ‡ãƒ«å¤§å­¦ã‚’å’æ¥­ã—ã¾ã—ã¦ã€æœ¬å½“ã€ãƒ‡ã‚£ãƒ•ã‚§ãƒ³ã‚¹ã‚’ã‚„ã£ãŸã®ã¯ã€ã¤ã„2ã€3é€±é–“å‰ãªã‚“ã§ã™ã‘ã‚Œã©ã‚‚ã€ã‚‚ã¨ã‚‚ã¨ã¯ã‚³ãƒ¼ãƒãƒ«å¤§å­¦ã£ã¦ã€ãƒ‹ãƒ¥ãƒ¼ãƒ¨ãƒ¼ã‚¯å¸‚ã®åœŸäº•ä¸­ã®ä¼Šå‚ã£ã¦ã€
[45.00s -> 50.24s] ã‚³ãƒãƒ«å¤§å­¦ã®å®Ÿã¯2ã¤ã‚­ãƒ£ãƒ³ãƒ‘ã‚¹ãŒã‚ã‚Šã¾ã—ã¦
[50.24s -> 51.92s] ä¸€ã¤ã¯ä¼Šé˜ªã«ã‚ã‚‹ã‚“ã§ã™ã‘ã©
[51.92s -> 53.86s] ã‚‚ã†ä¸€ã¤ã¯ãƒ‹ãƒ¥ãƒ¼ãƒ¨ãƒ¼ã‚¯å¸‚ã«ã‚ã‚‹
[53.86s -> 53.94s] ã‚¤ãƒ³ã‚¦ã‚£ãƒ¼ã‚¯å¸‚ã«ã‚ã‚‹
[53.94s -> 57.94s] ã‚¤ãƒ¼ã‚¹ãƒˆå·ã®ä¸Šã«æµ®ã„ã¦ã„ã‚‹ãƒ«ãƒ¼ã‚ºãƒ™ãƒ«ãƒˆå³¶ã£ã¦ã„ã†
[57.94s -> 59.96s] ã™ã”ã„ç´°é•·ã„å³¶ãŒã‚ã‚‹
[60.00s -> 62.84s] ãã“ã§PHEã‚’ã‚„ã£ã¦ãŠã‚Šã¾ã—ãŸ
[62.84s -> 65.70s] ç§ã¯å°å³¶ã£ã¦ã„ã†åå‰ãªã‚“ã§ã™ã‘ã©ã‚‚
[65.70s -> 67.00s] æœ¬å½“ã«ã—ã‚‡ã†ã‚‚ãªã„ãƒã‚¿ã‚’è¨€ã†ã¨
[67.00s -> 69.00s] å°å³¶ã®ä¸Šã§PHUãŒå¹ã„ãŸã¨
[69.00s -> 72.86s] ãã†ã„ã†ä¸¡é¢æ„Ÿã¨ãªã£ã¦ãŠã‚Šã¾ã™
[75.00s -> 77.72s] å°‚é–€éƒ¨å±‹ã¨ã—ã¦ã¯ãƒãƒ«ãƒãƒ¢ãƒ€ãƒªãƒ†ã‚£ãƒ¼ã¨å‘¼ã°ã‚Œã‚‹
[77.72s -> 80.18s] è‡ªç„¶è¨€èªã®ã‚·ã‚¹ãƒ†ãƒ ã«ã©ã†ã‚„ã£ãŸã‚‰
[80.18s -> 83.64s] è¨€èªä»¥å¤–ã®æƒ…å ±ã‚’ä¾‹ãˆã°ç”»åƒã§ã‚ã£ãŸã‚Šã¨ã‹
[83.64s -> 86.06s] éŸ³å£°ã¨ã„ã£ãŸã‚‚ã®ã‚’ç†è§£ã§ãã‚‹ã‚ˆã†ã«ã•ã›ã‚‹
[86.06s -> 87.54s] ãã†ã„ã£ãŸã“ã¨ã§ã‚ã£ãŸã‚Šã¨ã‹
[87.54s -> 90.00s] ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã¨å‘¼ã°ã‚Œã‚‹
[90.00s -> 94.38s] æœ€è¿‘RHFã¿ãŸã„ãªè¨€è‘‰ãŒã‚ˆãä½¿ã‚ã‚Œã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã‘ã©
[94.38s -> 95.78s] äººã‚’ã©ã†çµ¡ã‚ã¦
[95.78s -> 98.04s] NLPã®ã‚·ã‚¹ãƒ†ãƒ ã‚’å‘ä¸Šã•ã›ã¦ã„ãã‹
[98.04s -> 103.72s] ãã†ã„ã£ãŸä»¶ã¯ãƒã‚®ãƒ³ã‚°ãƒ•ã‚§ãƒ¼ã‚¹ã§
[105.00s -> 110.24s] å­¦éƒ¨ã‹ã‚‰å®Ÿã¯ã‚¢ãƒ¡ãƒªã‚«ã«è¡Œã£ã¦ã„ã¦
[110.24s -> 114.16s] ãƒŸã‚·ã‚¬ãƒ³å·ã«ã‚ã‚‹ãƒŸã‚·ã‚¬ãƒ³å¤§å­¦ã‚¢ãƒŠãƒ¼ãƒãƒ¼ã‚³ã¨ã„ã†ã¨ã“ã‚ãŒã‚ã‚‹ã‚“ã§ã™ã‘ã©ã‚‚
[114.16s -> 117.24s] ãã“ã§å­¦éƒ¨ã‚’ã‚„ã£ã¦ã„ã¦é«˜æ ¡ã¾ã§æ—¥æœ¬ã«è¡Œãã¾ã—ãŸ
[117.24s -> 120.00s] ãã†ã„ã£ãŸã¨ã“ã‚ã§ç«ç½ã«ãƒãƒˆãƒ³ãƒ€ãƒƒãƒã•ã›ã¦ã„ãŸã ãã¾ã™
[120.00s -> 122.00s] ä»Šæ—¥ã¯ã‚ˆã‚ã—ããŠé¡˜ã„ã—ã¾ã™
[135.00s -> 139.68s] ãã¡ã‚‰ã®æ–¹ã§ãƒªã‚µãƒ¼ãƒãƒ£ãƒ¼ã‚·ã‚¹ãƒˆãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚µãƒ¼ã¨ã„ã†ä»•äº‹ã‚’æŒã¡ã ã‹ã‚‰
[139.68s -> 143.54s] å°å³¶ã¨å…±ã«è¨€è‘‰ãƒ†ã‚¯ãƒ­ã‚¸ã«å–ã‚Šçµ„ã‚“ã§ã„ã‚‹ã¨ã„ã†çŠ¶æ³ã®ã§ã™
[143.54s -> 148.04s] ç§ã‚‚æœ¬å½“ã«PHDã‚‚æ‰‹ããŸã¦å£°ã¨ã„ã†ã‹
[148.04s -> 149.20s] æœ€è¿‘æ’®ã‚Šã¾ã—ã¦
[150.00s -> 155.20s] å…ˆæœˆ8æœˆã«ç„¡äº‹ã‚·ã‚¢ãƒˆãƒ«ã§ã™ã­è¥¿æµ·éƒ¨ã®ã‚·ã‚¢ãƒˆãƒ«ã«ã‚ã‚‹ãƒ¯ã‚·ãƒ³ãƒˆãƒ³å¤§å­¦ã§
[155.20s -> 157.68s] ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚µã‚¤ãƒ³ã‚¹ã®åšå£«èª²ç¨‹ã‚’å’æ¥­ã—ã¾ã—ãŸ
[157.68s -> 163.54s] ç ”ç©¶åˆ†é‡ã¨ã—ã¦ã¯æœ€åˆã®æ–¹ã¯æ©Ÿæ¢°ç¿»è¨³ã¨ã‹
[163.54s -> 165.04s] ã‚ã¨ã¯åŠ¹ç‡åŒ–ã¨ã—ã¦ã¯
[165.00s -> 168.30s] ãã®è¨€èªç”Ÿæˆã¨ã‹ãã®è¨€èªç”Ÿæˆã®ã‚¤ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã‹
[168.30s -> 169.72s] ãã†ã„ã†ã“ã¨ã‚’ã‚„ã£ã¦ãŠã‚Šã¾ã—ãŸ
[169.72s -> 171.44s] ã¡ã‚‡ã£ã¨é¡ã‚‹ã¨ã§ã™ã­
[171.44s -> 174.68s] å®Ÿã¯ç§ã‚‚ã²ã¾ã¨è¦‹ãŸå½¢ã§
[174.68s -> 179.44s] é«˜æ ¡å’æ¥­å¾Œã¯å¤§å­¦ã¯ã‚¢ãƒ¡ãƒªã‚«ã®ã‚¤ã‚¨ãƒ«å¤§å­¦ã¨ã„ã†
[180.00s -> 184.40s] å½“æ™‚ã¯çµ±è¨ˆå­¦éƒ¨ã‚’å’æ¥­ã—ã¾ã—ã¦
[184.40s -> 187.10s] ãã®å¾ŒELã§åƒããªãŒã‚‰
[187.10s -> 189.72s] ãƒ¯ã‚·ãƒ³ã‚³å¤§å­¦ã«é€²å­¦ã—ãŸã¨ã„ã†çµŒç†ã§ã™ã­
[189.72s -> 192.14s] æœ€è¿‘ã‚¤ãƒ¼ãƒ«å¤§å­¦ã‚‚çŸ¥ååº¦ãŒä¸ŠãŒã£ã¦ãã¦
[192.14s -> 193.62s] ã¡ã‚‡ã£ã¨ã‚ˆãåˆ†ã‹ã‚‰ãªã„æ•™æˆãŒ
[193.62s -> 194.96s] ã„ã‚ã‚“ãªç•ªçµ„ã§ãŠè©±ã—
[195.00s -> 198.00s] åå‰ã¯èª“ã„ã•ã›ã¦ã„ãŸã ãã¾ã™ã‘ã©ã‚‚
[198.00s -> 200.40s] ã¾ã‚ãªã‚“ã‹çŸ¥ååº¦ãŒãƒ©ãƒ•ã‚£ãƒƒã‚¯ã§å¬‰ã—ã„ã‚“ã§ã™ãŒ
[200.40s -> 203.00s] ã“ã“ã¯ã‚²ãƒ«ã®ã‚¿ãƒƒã‚¯ã‚¹ã§
[203.00s -> 204.80s] ã‚ªãƒ•ã‚½ãƒ¼ãƒ‰ã¨ã‹ã‚±ãƒ³ãƒ–ãƒªãƒƒã‚·ãƒ¥ã¨ç”Ÿã¾ã‚Œã¦
[204.80s -> 206.76s] ã“ã‚Œã‚ã–ã¨ãªã‚“ã‹ã‚„ã‚ãŸã‚Šã—ã¦ã‚‹ã‚“ã§ã™ã‚ˆã­
(venv) PS C:\Users\YN\huggingface_project> python sample.py
[2024-12-23 02:44:16.899] [ctranslate2] [thread 24832] [warning] The compute type inferred from the saved model is float16, but the target device or backend do not support efficient float16 computation. The model weights have been automatically converted to use the float32 compute type instead.
Transcription saved to transcription_output.txt
(venv) PS C:\Users\YN\huggingface_project> python sample.py
[2024-12-23 02:49:35.232] [ctranslate2] [thread 27968] [warning] The compute type inferred from the saved model is float16, but the target device or backend do not support efficient float16 computation. The model weights have been automatically converted to use the float32 compute type instead.
Traceback (most recent call last):
  File "C:\Users\YN\huggingface_project\sample.py", line 20, in <module>
    total_segments = len(segments)
                     ^^^^^^^^^^^^^
TypeError: object of type 'generator' has no len()
(venv) PS C:\Users\YN\huggingface_project> pyton sample.py
pyton : ç”¨èª 'pyton' ã¯ã€ã‚³ãƒãƒ³ãƒ‰ãƒ¬ãƒƒãƒˆã€é–¢æ•°ã€ã‚¹ã‚¯ãƒªãƒ—ãƒˆ ãƒ•ã‚¡ã‚¤ãƒ«ã€ã¾ãŸã¯æ“ä½œå¯èƒ½ãªãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®åå‰ã¨ã—ã¦èªè­˜ã•ã‚Œã¾ã›ã‚“ã€‚åå‰ãŒæ­£ã—ãè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã€ãƒ‘ã‚¹ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯ãã®ãƒ‘ã‚¹ãŒæ­£ã—ã„ã“ã¨ã‚’ç¢ºèªã—ã¦ã‹ã‚‰ã€å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚
ç™ºç”Ÿå ´æ‰€ è¡Œ:1 æ–‡å­—:1
+ pyton sample.py
+ ~~~~~
    + CategoryInfo          : ObjectNotFound: (pyton:String) [], CommandNotFoundException
    + FullyQualifiedErrorId : CommandNotFoundException

(venv) PS C:\Users\YN\huggingface_project> python sample.py
[2024-12-23 02:50:37.413] [ctranslate2] [thread 31856] [warning] The compute type inferred from the saved model is float16, but the target device or backend do not support efficient float16 computation. The model weights have been automatically converted to use the float32 compute type instead.
[##################################################] 100.00% å®Œäº†
Transcription saved to transcription_output.txt
(venv) PS C:\Users\YN\huggingface_project> python samole.py
C:\Users\YN\AppData\Local\Programs\Python\Python312\python.exe: can't open file 'C:\\Users\\YN\\huggingface_project\\samole.py': [Errno 2] No such file or directory
(venv) PS C:\Users\YN\huggingface_project> python sample.py
[2024-12-23 02:57:56.041] [ctranslate2] [thread 30424] [warning] The compute type inferred from the saved model is float16, but the target device or backend do not support efficient float16 computation. The model weights have been automatically converted to use the float32 compute type instead.
[##################################################] 100.00% å®Œäº†
Transcription saved to transcription_output_20241223_030046.txt
(venv) PS C:\Users\YN\huggingface_project> python sample.py
[2024-12-23 03:04:16.856] [ctranslate2] [thread 26592] [warning] The compute type inferred from the saved model is float16, but the target device or backend do not support efficient float16 computation. The model weights have been automatically converted to use the float32 compute type instead.
[##################################################] 100.00% å®Œäº†
Transcription saved to transcription_output_20241223_030709.txt
Failed to send webhook notification. Status code: 400
(venv) PS C:\Users\YN\huggingface_project> python sample.py
[2024-12-23 03:09:42.353] [ctranslate2] [thread 21984] [warning] The compute type inferred from the saved model is float16, but the target device or backend do not support efficient float16 computation. The model weights have been automatically converted to use the float32 compute type instead.
Transcription saved to transcription_output_20241223_030942.txt
Webhook notification sent successfully.
(venv) PS C:\Users\YN\huggingface_project>




```



### ç¾çŠ¶ã®sample.py

```python

import requests
from datetime import datetime
from faster_whisper import WhisperModel

# Webhook URLï¼ˆè‡ªåˆ†ã®Discord Webhook URLã«ç½®ãæ›ãˆã¦ãã ã•ã„ï¼‰
WEBHOOK_URL = "ã“ã“ã«WebhookURLã‚’å…¥ã‚Œã‚‹"

# ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
model = WhisperModel("kotoba-tech/kotoba-whisper-v2.0-faster")

# éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—èµ·ã“ã—
segments, info = model.transcribe("sample_ja_speech.wav", language="ja", chunk_length=15, condition_on_previous_text=False)

# å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã«ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’è¿½åŠ 
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
output_filename = f"transcription_output_{timestamp}.txt"

# ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚€
with open(output_filename, "w", encoding="utf-8") as file:
    for segment in segments:
        # å„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®é–‹å§‹æ™‚åˆ»ã€çµ‚äº†æ™‚åˆ»ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
        file.write("[%.2fs -> %.2fs] %s\n" % (segment.start, segment.end, segment.text))

print(f"Transcription saved to {output_filename}")

# Webhookã«é€ä¿¡ã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
message = {
    "content": f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—èµ·ã“ã—ãŒå®Œäº†ã—ã¾ã—ãŸï¼\n"
               f"ä½¿ç”¨ã—ãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«: sample_ja_speech.wav\n"
               f"å‡ºåŠ›ã—ãŸãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: {output_filename}\n"
               f"å‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸã€‚"
}

# Webhooké€šçŸ¥ã‚’é€ä¿¡
response = requests.post(WEBHOOK_URL, json=message)

# Webhooké€ä¿¡çµæœã®ç¢ºèª
if response.status_code == 204:
    print("Webhook notification sent successfully.")
else:
    print(f"Failed to send webhook notification. Status code: {response.status_code}, Response: {response.text}")

```